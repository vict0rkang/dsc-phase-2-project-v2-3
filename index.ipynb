{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatiron Phase II Project\n",
    "### King's County \n",
    "\n",
    "## Introduction \n",
    "\n",
    "In this cumulative lab you'll perform a full linear regression analysis and report the findings of your final model, including both predictive model performance metrics and interpretation of fitted model parameters.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Perform linear regression analysis with iterative modeling\n",
    "* Evaluate your final model and interpret its predictive performance metrics\n",
    "* Apply an inferential lens to interpret relationships between variables identified by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Task: Develop a LEGO Pricing Algorithm\n",
    "\n",
    "![sold](images/SOLD.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "\n",
    "You just got hired by LEGO! Your first project is going to be to develop a pricing algorithm to help set a target price for new LEGO sets that are released to market. The goal is to save the company some time and to help ensure consistency in pricing between new products and past products.\n",
    "\n",
    "The main purpose of this algorithm is *predictive*, meaning that **your model should be able to take in attributes of a LEGO set that does not yet have a set price, and to predict a good price**. The effectiveness of your predictive model will be measured by how well it predicts prices in our test set, where we know what the actual prices were but the model does not.\n",
    "\n",
    "The secondary purpose of this algorithm is *inferential*, meaning that **your model should be able to tell us something about the relationship between the attributes of a LEGO set and its price**. You will apply your knowledge of statistics to include appropriate caveats about these relationships.\n",
    "\n",
    "### Data Understanding\n",
    "\n",
    "You have access to a dataset containing over 700 LEGO sets released in the past, including attributes of those sets as well as their prices. You can assume that the numeric attributes in this dataset have already been preprocessed appropriately for modeling (i.e. that there are no missing or invalid values), while the text attributes are simply there for your visual inspection and should not be used for modeling. Also, note that some of these attributes cannot be used in your analysis because they will be unavailable for future LEGO products or are otherwise irrelevant.\n",
    "\n",
    "You do not need to worry about inflation or differences in currency; just predict the same kinds of prices as are present in the past data, which have already been converted to USD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Outline\n",
    "\n",
    "#### 1. Exploratory Data Anaylsis (EDA) & Data Cleaning\n",
    "\n",
    "Load and Explore the data. Then, clean and prepare data for modelling. Include feature engineering to enhance analysis.\n",
    "\n",
    "#### 2. Regression Modeling\n",
    "\n",
    "You'll start modeling by choosing the feature that is most correlated with our target, and build and evaluate a linear regression model with just that feature.\n",
    "\n",
    "Now, add in the rest of the relevant numeric features of the training data, and compare that model's performance to the performance of the baseline model.\n",
    "\n",
    "Using statistical properties of the fitted model, the `sklearn.feature_selection` submodule, and some custom code, find the combination of relevant numeric features that produces the best scores.\n",
    "\n",
    "#### 3. Regression Results\n",
    "\n",
    "\n",
    "Using the best features selected in the previous step, create a final model, fit it on all rows of the training dataset, and evaluate it on all rows of the test dataset in terms of both r-squared and RMSE.\n",
    "\n",
    "Determine what, if any, understanding of the underlying relationship between variables can be determined with this model. This means you will need to interpret the model coefficients as well as checking whether the assumptions of linear regression have been met.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploratory Data Analysis (EDA)\n",
    "\n",
    "### Loading the Data\n",
    "\n",
    "In the cells below, we load both the train and test datasets for you. Remember, both of these datasets contain prices, but we are using the test set as a stand-in for future LEGO products where the price has not yet been determined. The model will be trained on just the train set, then we will compare its predictions on the test set to the actual prices on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             21597 non-null  int64  \n",
      " 1   date           21597 non-null  object \n",
      " 2   price          21597 non-null  float64\n",
      " 3   bedrooms       21597 non-null  int64  \n",
      " 4   bathrooms      21597 non-null  float64\n",
      " 5   sqft_living    21597 non-null  int64  \n",
      " 6   sqft_lot       21597 non-null  int64  \n",
      " 7   floors         21597 non-null  float64\n",
      " 8   waterfront     19221 non-null  object \n",
      " 9   view           21534 non-null  object \n",
      " 10  condition      21597 non-null  object \n",
      " 11  grade          21597 non-null  object \n",
      " 12  sqft_above     21597 non-null  int64  \n",
      " 13  sqft_basement  21597 non-null  object \n",
      " 14  yr_built       21597 non-null  int64  \n",
      " 15  yr_renovated   17755 non-null  float64\n",
      " 16  zipcode        21597 non-null  int64  \n",
      " 17  lat            21597 non-null  float64\n",
      " 18  long           21597 non-null  float64\n",
      " 19  sqft_living15  21597 non-null  int64  \n",
      " 20  sqft_lot15     21597 non-null  int64  \n",
      "dtypes: float64(6), int64(9), object(6)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/kc_house_data.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 21597 rows in the dataframe, each row representing a home sale in Kings County.\n",
    "Each row has twenty (20) columns, each column representing a feature of the home sale.\n",
    "\n",
    "By looking at the Non-Null count, we know columns **waterfront, view**, and **yr_renovated** have missing data.\n",
    "\n",
    "We also note the columns curiously stored as objects,such as **date** and **sqft_basement**, which will need further investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names are mostly self-explanatory. Below are further definitions for two of the columns that weren't as clear. For even further defintions, please see *column_names.md* included with the data in the Data folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**BUILDING CONDITION**\n",
    ">    \tRelative to age and grade. Coded 1-5.\n",
    ">\n",
    ">1 = Poor- Worn out. Repair and overhaul needed on painted surfaces, roofing, plumbing, heating and numerous functional inadequacies. >Excessive deferred maintenance and abuse, limited value-in-use, approaching abandonment or major reconstruction; reuse or change in >occupancy is imminent. Effective age is near the end of the scale regardless of the actual chronological age.\n",
    ">\n",
    ">2 = Fair- Badly worn. Much repair needed. Many items need refinishing or overhauling, deferred maintenance obvious, inadequate building >utility and systems all shortening the life expectancy and increasing the effective age.\n",
    ">\n",
    ">3 = Average- Some evidence of deferred maintenance and normal obsolescence with age in that a few minor repairs are needed, along with some refinishing. All major components still functional and contributing toward an extended life expectancy. Effective age and utility is standard for like properties of its class and usage.\n",
    ">\n",
    ">4 = Good- No obvious maintenance required but neither is everything new. Appearance and utility are above the standard and the overall effective age will be lower than the typical property.\n",
    ">\n",
    ">5= Very Good- All items well maintained, many having been overhauled and repaired as they have shown signs of wear, increasing the life expectancy and lowering the effective age with little deterioration or obsolescence evident with a high degree of utility.\n",
    ">\n",
    "\n",
    "\n",
    ">**BUILDING GRADE**\n",
    ">    \tRepresents the construction quality of improvements. Grades run from grade 1 to 13. \n",
    "        Generally defined as:\n",
    ">\n",
    ">1-3 Falls short of minimum building standards. Normally cabin or inferior structure.\n",
    ">\n",
    ">4 Generally older, low quality construction. Does not meet code.\n",
    ">\n",
    ">5 Low construction costs and workmanship. Small, simple design.\n",
    ">\n",
    ">6 Lowest grade currently meeting building code. Low quality materials and simple designs.\n",
    ">\n",
    ">7 Average grade of construction and design. Commonly seen in plats and older sub-divisions.\n",
    ">\n",
    ">8 Just above average in construction and design. Usually better materials in both the exterior and interior finish work.\n",
    ">\n",
    ">9 Better architectural design with extra interior and exterior design and quality.\n",
    ">\n",
    ">10 Homes of this quality generally have high quality features. Finish work is better and more design quality is seen in the floor plans. Generally have a larger square footage.\n",
    ">\n",
    ">11 Custom design and higher quality finish work with added amenities of solid woods, bathroom fixtures and more luxurious options.\n",
    ">\n",
    ">12 Custom design and excellent builders. All materials are of the highest quality and all conveniences are present.\n",
    ">\n",
    ">13 Generally custom designed and built. Mansion level. Large amount of highest quality cabinet work, wood trim, marble, entry ways etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Data Cleaning & Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import cross_validate, ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/13/2014</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>2170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/25/2015</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>6 Low Average</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1050</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2/18/2015</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21592</th>\n",
       "      <td>5/21/2014</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>1530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21593</th>\n",
       "      <td>2/23/2015</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>2310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21594</th>\n",
       "      <td>6/23/2014</td>\n",
       "      <td>402101.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21595</th>\n",
       "      <td>1/16/2015</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>1600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21596</th>\n",
       "      <td>10/15/2014</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21597 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date     price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
       "0      10/13/2014  221900.0         3       1.00         1180      5650   \n",
       "1       12/9/2014  538000.0         3       2.25         2570      7242   \n",
       "2       2/25/2015  180000.0         2       1.00          770     10000   \n",
       "3       12/9/2014  604000.0         4       3.00         1960      5000   \n",
       "4       2/18/2015  510000.0         3       2.00         1680      8080   \n",
       "...           ...       ...       ...        ...          ...       ...   \n",
       "21592   5/21/2014  360000.0         3       2.50         1530      1131   \n",
       "21593   2/23/2015  400000.0         4       2.50         2310      5813   \n",
       "21594   6/23/2014  402101.0         2       0.75         1020      1350   \n",
       "21595   1/16/2015  400000.0         3       2.50         1600      2388   \n",
       "21596  10/15/2014  325000.0         2       0.75         1020      1076   \n",
       "\n",
       "       floors waterfront  view  condition          grade  sqft_above  \\\n",
       "0         1.0        NaN  NONE    Average      7 Average        1180   \n",
       "1         2.0         NO  NONE    Average      7 Average        2170   \n",
       "2         1.0         NO  NONE    Average  6 Low Average         770   \n",
       "3         1.0         NO  NONE  Very Good      7 Average        1050   \n",
       "4         1.0         NO  NONE    Average         8 Good        1680   \n",
       "...       ...        ...   ...        ...            ...         ...   \n",
       "21592     3.0         NO  NONE    Average         8 Good        1530   \n",
       "21593     2.0         NO  NONE    Average         8 Good        2310   \n",
       "21594     2.0         NO  NONE    Average      7 Average        1020   \n",
       "21595     2.0        NaN  NONE    Average         8 Good        1600   \n",
       "21596     2.0         NO  NONE    Average      7 Average        1020   \n",
       "\n",
       "      sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0               0.0      1955           0.0    98178  47.5112 -122.257   \n",
       "1             400.0      1951        1991.0    98125  47.7210 -122.319   \n",
       "2               0.0      1933           NaN    98028  47.7379 -122.233   \n",
       "3             910.0      1965           0.0    98136  47.5208 -122.393   \n",
       "4               0.0      1987           0.0    98074  47.6168 -122.045   \n",
       "...             ...       ...           ...      ...      ...      ...   \n",
       "21592           0.0      2009           0.0    98103  47.6993 -122.346   \n",
       "21593           0.0      2014           0.0    98146  47.5107 -122.362   \n",
       "21594           0.0      2009           0.0    98144  47.5944 -122.299   \n",
       "21595           0.0      2004           0.0    98027  47.5345 -122.069   \n",
       "21596           0.0      2008           0.0    98144  47.5941 -122.299   \n",
       "\n",
       "       sqft_living15  sqft_lot15  \n",
       "0               1340        5650  \n",
       "1               1690        7639  \n",
       "2               2720        8062  \n",
       "3               1360        5000  \n",
       "4               1800        7503  \n",
       "...              ...         ...  \n",
       "21592           1530        1509  \n",
       "21593           1830        7200  \n",
       "21594           1020        2007  \n",
       "21595           1410        1287  \n",
       "21596           1020        1357  \n",
       "\n",
       "[21597 rows x 20 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/13/2014</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>2170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/25/2015</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>6 Low Average</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1050</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2/18/2015</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21592</th>\n",
       "      <td>5/21/2014</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>1530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21593</th>\n",
       "      <td>2/23/2015</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>2310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21594</th>\n",
       "      <td>6/23/2014</td>\n",
       "      <td>402101.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21595</th>\n",
       "      <td>1/16/2015</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>1600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21596</th>\n",
       "      <td>10/15/2014</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21597 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date     price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
       "0      10/13/2014  221900.0         3       1.00         1180      5650   \n",
       "1       12/9/2014  538000.0         3       2.25         2570      7242   \n",
       "2       2/25/2015  180000.0         2       1.00          770     10000   \n",
       "3       12/9/2014  604000.0         4       3.00         1960      5000   \n",
       "4       2/18/2015  510000.0         3       2.00         1680      8080   \n",
       "...           ...       ...       ...        ...          ...       ...   \n",
       "21592   5/21/2014  360000.0         3       2.50         1530      1131   \n",
       "21593   2/23/2015  400000.0         4       2.50         2310      5813   \n",
       "21594   6/23/2014  402101.0         2       0.75         1020      1350   \n",
       "21595   1/16/2015  400000.0         3       2.50         1600      2388   \n",
       "21596  10/15/2014  325000.0         2       0.75         1020      1076   \n",
       "\n",
       "       floors waterfront  view  condition          grade  sqft_above  \\\n",
       "0         1.0        NaN  NONE    Average      7 Average        1180   \n",
       "1         2.0         NO  NONE    Average      7 Average        2170   \n",
       "2         1.0         NO  NONE    Average  6 Low Average         770   \n",
       "3         1.0         NO  NONE  Very Good      7 Average        1050   \n",
       "4         1.0         NO  NONE    Average         8 Good        1680   \n",
       "...       ...        ...   ...        ...            ...         ...   \n",
       "21592     3.0         NO  NONE    Average         8 Good        1530   \n",
       "21593     2.0         NO  NONE    Average         8 Good        2310   \n",
       "21594     2.0         NO  NONE    Average      7 Average        1020   \n",
       "21595     2.0        NaN  NONE    Average         8 Good        1600   \n",
       "21596     2.0         NO  NONE    Average      7 Average        1020   \n",
       "\n",
       "      sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0               0.0      1955           0.0    98178  47.5112 -122.257   \n",
       "1             400.0      1951        1991.0    98125  47.7210 -122.319   \n",
       "2               0.0      1933           NaN    98028  47.7379 -122.233   \n",
       "3             910.0      1965           0.0    98136  47.5208 -122.393   \n",
       "4               0.0      1987           0.0    98074  47.6168 -122.045   \n",
       "...             ...       ...           ...      ...      ...      ...   \n",
       "21592           0.0      2009           0.0    98103  47.6993 -122.346   \n",
       "21593           0.0      2014           0.0    98146  47.5107 -122.362   \n",
       "21594           0.0      2009           0.0    98144  47.5944 -122.299   \n",
       "21595           0.0      2004           0.0    98027  47.5345 -122.069   \n",
       "21596           0.0      2008           0.0    98144  47.5941 -122.299   \n",
       "\n",
       "       sqft_living15  sqft_lot15  \n",
       "0               1340        5650  \n",
       "1               1690        7639  \n",
       "2               2720        8062  \n",
       "3               1360        5000  \n",
       "4               1800        7503  \n",
       "...              ...         ...  \n",
       "21592           1530        1509  \n",
       "21593           1830        7200  \n",
       "21594           1020        2007  \n",
       "21595           1410        1287  \n",
       "21596           1020        1357  \n",
       "\n",
       "[21597 rows x 20 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop ID column as we don't need it\n",
    "\n",
    "df = df.drop(['id'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 20 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   date           21597 non-null  datetime64[ns]\n",
      " 1   price          21597 non-null  float64       \n",
      " 2   bedrooms       21597 non-null  int64         \n",
      " 3   bathrooms      21597 non-null  float64       \n",
      " 4   sqft_living    21597 non-null  int64         \n",
      " 5   sqft_lot       21597 non-null  int64         \n",
      " 6   floors         21597 non-null  float64       \n",
      " 7   waterfront     19221 non-null  object        \n",
      " 8   view           21534 non-null  object        \n",
      " 9   condition      21597 non-null  object        \n",
      " 10  grade          21597 non-null  object        \n",
      " 11  sqft_above     21597 non-null  int64         \n",
      " 12  sqft_basement  21597 non-null  object        \n",
      " 13  yr_built       21597 non-null  int64         \n",
      " 14  yr_renovated   17755 non-null  float64       \n",
      " 15  zipcode        21597 non-null  int64         \n",
      " 16  lat            21597 non-null  float64       \n",
      " 17  long           21597 non-null  float64       \n",
      " 18  sqft_living15  21597 non-null  int64         \n",
      " 19  sqft_lot15     21597 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(6), int64(8), object(5)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# change the date column from a string to a datetime datatype\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Engineering!**\n",
    "\n",
    "The Date column is defined as the date when a Home has been sold. The exact sale date itself will not be particularly interesting for our analysis of the sale price; however, using that date, we could potentially find some other interesting variables about that home sale such as:\n",
    "\n",
    "* Month of the year when the home sale occured (seasonal price swings?) \n",
    "\n",
    "* Home's Age at the time of sale?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>...</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>month_sold</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>age_when_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-10-13</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>1955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-12-09</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-25</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>1933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-12-09</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>...</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-18</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21592</th>\n",
       "      <td>2014-05-21</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "      <td>5</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21593</th>\n",
       "      <td>2015-02-23</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21594</th>\n",
       "      <td>2014-06-23</td>\n",
       "      <td>402101.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>2007</td>\n",
       "      <td>6</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21595</th>\n",
       "      <td>2015-01-16</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21596</th>\n",
       "      <td>2014-10-15</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21597 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date     price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
       "0     2014-10-13  221900.0         3       1.00         1180      5650   \n",
       "1     2014-12-09  538000.0         3       2.25         2570      7242   \n",
       "2     2015-02-25  180000.0         2       1.00          770     10000   \n",
       "3     2014-12-09  604000.0         4       3.00         1960      5000   \n",
       "4     2015-02-18  510000.0         3       2.00         1680      8080   \n",
       "...          ...       ...       ...        ...          ...       ...   \n",
       "21592 2014-05-21  360000.0         3       2.50         1530      1131   \n",
       "21593 2015-02-23  400000.0         4       2.50         2310      5813   \n",
       "21594 2014-06-23  402101.0         2       0.75         1020      1350   \n",
       "21595 2015-01-16  400000.0         3       2.50         1600      2388   \n",
       "21596 2014-10-15  325000.0         2       0.75         1020      1076   \n",
       "\n",
       "       floors waterfront  view  condition  ... yr_built  yr_renovated zipcode  \\\n",
       "0         1.0        NaN  NONE    Average  ...     1955           0.0   98178   \n",
       "1         2.0         NO  NONE    Average  ...     1951        1991.0   98125   \n",
       "2         1.0         NO  NONE    Average  ...     1933           NaN   98028   \n",
       "3         1.0         NO  NONE  Very Good  ...     1965           0.0   98136   \n",
       "4         1.0         NO  NONE    Average  ...     1987           0.0   98074   \n",
       "...       ...        ...   ...        ...  ...      ...           ...     ...   \n",
       "21592     3.0         NO  NONE    Average  ...     2009           0.0   98103   \n",
       "21593     2.0         NO  NONE    Average  ...     2014           0.0   98146   \n",
       "21594     2.0         NO  NONE    Average  ...     2009           0.0   98144   \n",
       "21595     2.0        NaN  NONE    Average  ...     2004           0.0   98027   \n",
       "21596     2.0         NO  NONE    Average  ...     2008           0.0   98144   \n",
       "\n",
       "           lat     long  sqft_living15  sqft_lot15  month_sold  year_sold  \\\n",
       "0      47.5112 -122.257           1340        5650          10       2014   \n",
       "1      47.7210 -122.319           1690        7639          12       2014   \n",
       "2      47.7379 -122.233           2720        8062           2       2015   \n",
       "3      47.5208 -122.393           1360        5000          12       2014   \n",
       "4      47.6168 -122.045           1800        7503           2       2015   \n",
       "...        ...      ...            ...         ...         ...        ...   \n",
       "21592  47.6993 -122.346           1530        1509           5       2014   \n",
       "21593  47.5107 -122.362           1830        7200           2       2015   \n",
       "21594  47.5944 -122.299           1020        2007           6       2014   \n",
       "21595  47.5345 -122.069           1410        1287           1       2015   \n",
       "21596  47.5941 -122.299           1020        1357          10       2014   \n",
       "\n",
       "       age_when_sold  \n",
       "0                 59  \n",
       "1                 63  \n",
       "2                 82  \n",
       "3                 49  \n",
       "4                 28  \n",
       "...              ...  \n",
       "21592              5  \n",
       "21593              1  \n",
       "21594              5  \n",
       "21595             11  \n",
       "21596              6  \n",
       "\n",
       "[21597 rows x 23 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the converted datetime data to create new columns identifying month sold and year sold.\n",
    "\n",
    "df['month_sold'] = df['date'].dt.month\n",
    "df['year_sold'] = df['date'].dt.year\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>...</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>month_sold</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>age_when_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-10-13</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>1955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-12-09</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-25</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>1933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-12-09</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>...</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-18</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21592</th>\n",
       "      <td>2014-05-21</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "      <td>5</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21593</th>\n",
       "      <td>2015-02-23</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21594</th>\n",
       "      <td>2014-06-23</td>\n",
       "      <td>402101.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>2007</td>\n",
       "      <td>6</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21595</th>\n",
       "      <td>2015-01-16</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21596</th>\n",
       "      <td>2014-10-15</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21597 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date     price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
       "0     2014-10-13  221900.0         3       1.00         1180      5650   \n",
       "1     2014-12-09  538000.0         3       2.25         2570      7242   \n",
       "2     2015-02-25  180000.0         2       1.00          770     10000   \n",
       "3     2014-12-09  604000.0         4       3.00         1960      5000   \n",
       "4     2015-02-18  510000.0         3       2.00         1680      8080   \n",
       "...          ...       ...       ...        ...          ...       ...   \n",
       "21592 2014-05-21  360000.0         3       2.50         1530      1131   \n",
       "21593 2015-02-23  400000.0         4       2.50         2310      5813   \n",
       "21594 2014-06-23  402101.0         2       0.75         1020      1350   \n",
       "21595 2015-01-16  400000.0         3       2.50         1600      2388   \n",
       "21596 2014-10-15  325000.0         2       0.75         1020      1076   \n",
       "\n",
       "       floors waterfront  view  condition  ... yr_built  yr_renovated zipcode  \\\n",
       "0         1.0        NaN  NONE    Average  ...     1955           0.0   98178   \n",
       "1         2.0         NO  NONE    Average  ...     1951        1991.0   98125   \n",
       "2         1.0         NO  NONE    Average  ...     1933           NaN   98028   \n",
       "3         1.0         NO  NONE  Very Good  ...     1965           0.0   98136   \n",
       "4         1.0         NO  NONE    Average  ...     1987           0.0   98074   \n",
       "...       ...        ...   ...        ...  ...      ...           ...     ...   \n",
       "21592     3.0         NO  NONE    Average  ...     2009           0.0   98103   \n",
       "21593     2.0         NO  NONE    Average  ...     2014           0.0   98146   \n",
       "21594     2.0         NO  NONE    Average  ...     2009           0.0   98144   \n",
       "21595     2.0        NaN  NONE    Average  ...     2004           0.0   98027   \n",
       "21596     2.0         NO  NONE    Average  ...     2008           0.0   98144   \n",
       "\n",
       "           lat     long  sqft_living15  sqft_lot15  month_sold  year_sold  \\\n",
       "0      47.5112 -122.257           1340        5650          10       2014   \n",
       "1      47.7210 -122.319           1690        7639          12       2014   \n",
       "2      47.7379 -122.233           2720        8062           2       2015   \n",
       "3      47.5208 -122.393           1360        5000          12       2014   \n",
       "4      47.6168 -122.045           1800        7503           2       2015   \n",
       "...        ...      ...            ...         ...         ...        ...   \n",
       "21592  47.6993 -122.346           1530        1509           5       2014   \n",
       "21593  47.5107 -122.362           1830        7200           2       2015   \n",
       "21594  47.5944 -122.299           1020        2007           6       2014   \n",
       "21595  47.5345 -122.069           1410        1287           1       2015   \n",
       "21596  47.5941 -122.299           1020        1357          10       2014   \n",
       "\n",
       "       age_when_sold  \n",
       "0                 59  \n",
       "1                 63  \n",
       "2                 82  \n",
       "3                 49  \n",
       "4                 28  \n",
       "...              ...  \n",
       "21592              5  \n",
       "21593              1  \n",
       "21594              5  \n",
       "21595             11  \n",
       "21596              6  \n",
       "\n",
       "[21597 rows x 23 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the newly created year sold column and the yr built column to create new column showing age of home when sold\n",
    "\n",
    "df['age_when_sold'] = df['year_sold'] - df['yr_built']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 9      472\n",
       " 8      443\n",
       " 11     431\n",
       " 0      430\n",
       " 10     428\n",
       "       ... \n",
       " 113     28\n",
       " 115     26\n",
       " 81      23\n",
       " 80      21\n",
       "-1       12\n",
       "Name: age_when_sold, Length: 117, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"age_when_sold\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>...</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>month_sold</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>age_when_sold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>2014-06-25</td>\n",
       "      <td>597326.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3570</td>\n",
       "      <td>8250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98040</td>\n",
       "      <td>47.5784</td>\n",
       "      <td>-122.226</td>\n",
       "      <td>2230</td>\n",
       "      <td>10000</td>\n",
       "      <td>6</td>\n",
       "      <td>2014</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685</th>\n",
       "      <td>2014-10-29</td>\n",
       "      <td>385195.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>710</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5756</td>\n",
       "      <td>-122.316</td>\n",
       "      <td>1440</td>\n",
       "      <td>4800</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>614285.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2730</td>\n",
       "      <td>6401</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98072</td>\n",
       "      <td>47.7685</td>\n",
       "      <td>-122.160</td>\n",
       "      <td>2520</td>\n",
       "      <td>6126</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8032</th>\n",
       "      <td>2014-06-24</td>\n",
       "      <td>455000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1200</td>\n",
       "      <td>1259</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.6001</td>\n",
       "      <td>-122.298</td>\n",
       "      <td>1320</td>\n",
       "      <td>1852</td>\n",
       "      <td>6</td>\n",
       "      <td>2014</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14475</th>\n",
       "      <td>2014-08-26</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1570</td>\n",
       "      <td>1269</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98199</td>\n",
       "      <td>47.6514</td>\n",
       "      <td>-122.385</td>\n",
       "      <td>1570</td>\n",
       "      <td>6000</td>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17084</th>\n",
       "      <td>2014-06-17</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1380</td>\n",
       "      <td>3600</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98122</td>\n",
       "      <td>47.6074</td>\n",
       "      <td>-122.305</td>\n",
       "      <td>1480</td>\n",
       "      <td>3600</td>\n",
       "      <td>6</td>\n",
       "      <td>2014</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19789</th>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>455000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1320</td>\n",
       "      <td>1014</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98122</td>\n",
       "      <td>47.6047</td>\n",
       "      <td>-122.305</td>\n",
       "      <td>1380</td>\n",
       "      <td>1495</td>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20754</th>\n",
       "      <td>2014-08-28</td>\n",
       "      <td>357000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2990</td>\n",
       "      <td>9240</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98133</td>\n",
       "      <td>47.7384</td>\n",
       "      <td>-122.348</td>\n",
       "      <td>1970</td>\n",
       "      <td>18110</td>\n",
       "      <td>8</td>\n",
       "      <td>2014</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20836</th>\n",
       "      <td>2014-07-09</td>\n",
       "      <td>595000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3730</td>\n",
       "      <td>4560</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6725</td>\n",
       "      <td>-122.330</td>\n",
       "      <td>1800</td>\n",
       "      <td>4560</td>\n",
       "      <td>7</td>\n",
       "      <td>2014</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20947</th>\n",
       "      <td>2014-07-31</td>\n",
       "      <td>230000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1040</td>\n",
       "      <td>1264</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5951</td>\n",
       "      <td>-122.301</td>\n",
       "      <td>1350</td>\n",
       "      <td>3000</td>\n",
       "      <td>7</td>\n",
       "      <td>2014</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21246</th>\n",
       "      <td>2014-11-25</td>\n",
       "      <td>559000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1650</td>\n",
       "      <td>960</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6611</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1650</td>\n",
       "      <td>3000</td>\n",
       "      <td>11</td>\n",
       "      <td>2014</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21356</th>\n",
       "      <td>2014-05-20</td>\n",
       "      <td>490000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4460</td>\n",
       "      <td>2975</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>AVERAGE</td>\n",
       "      <td>Average</td>\n",
       "      <td>...</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98119</td>\n",
       "      <td>47.6313</td>\n",
       "      <td>-122.370</td>\n",
       "      <td>2490</td>\n",
       "      <td>4231</td>\n",
       "      <td>5</td>\n",
       "      <td>2014</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date     price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
       "1761  2014-06-25  597326.0         4       4.00         3570      8250   \n",
       "2685  2014-10-29  385195.0         1       1.00          710      6000   \n",
       "7519  2014-12-31  614285.0         5       2.75         2730      6401   \n",
       "8032  2014-06-24  455000.0         2       1.50         1200      1259   \n",
       "14475 2014-08-26  500000.0         2       2.25         1570      1269   \n",
       "17084 2014-06-17  350000.0         3       2.00         1380      3600   \n",
       "19789 2014-08-01  455000.0         3       1.75         1320      1014   \n",
       "20754 2014-08-28  357000.0         5       2.50         2990      9240   \n",
       "20836 2014-07-09  595000.0         4       3.25         3730      4560   \n",
       "20947 2014-07-31  230000.0         3       1.50         1040      1264   \n",
       "21246 2014-11-25  559000.0         2       3.00         1650       960   \n",
       "21356 2014-05-20  490000.0         5       3.50         4460      2975   \n",
       "\n",
       "       floors waterfront     view condition  ... yr_built  yr_renovated  \\\n",
       "1761      2.0         NO     NONE   Average  ...     2015           NaN   \n",
       "2685      1.5         NO     NONE   Average  ...     2015           NaN   \n",
       "7519      2.0         NO     NONE   Average  ...     2015           0.0   \n",
       "8032      2.0         NO     NONE   Average  ...     2015           NaN   \n",
       "14475     2.0        NaN     NONE   Average  ...     2015           NaN   \n",
       "17084     3.0        NaN     NONE   Average  ...     2015           0.0   \n",
       "19789     3.0         NO     NONE   Average  ...     2015           0.0   \n",
       "20754     2.0         NO     NONE   Average  ...     2015           0.0   \n",
       "20836     2.0         NO     NONE   Average  ...     2015           0.0   \n",
       "20947     2.0         NO     NONE   Average  ...     2015           0.0   \n",
       "21246     3.0         NO     NONE   Average  ...     2015           NaN   \n",
       "21356     3.0         NO  AVERAGE   Average  ...     2015           NaN   \n",
       "\n",
       "      zipcode      lat     long  sqft_living15  sqft_lot15  month_sold  \\\n",
       "1761    98040  47.5784 -122.226           2230       10000           6   \n",
       "2685    98144  47.5756 -122.316           1440        4800          10   \n",
       "7519    98072  47.7685 -122.160           2520        6126          12   \n",
       "8032    98144  47.6001 -122.298           1320        1852           6   \n",
       "14475   98199  47.6514 -122.385           1570        6000           8   \n",
       "17084   98122  47.6074 -122.305           1480        3600           6   \n",
       "19789   98122  47.6047 -122.305           1380        1495           8   \n",
       "20754   98133  47.7384 -122.348           1970       18110           8   \n",
       "20836   98103  47.6725 -122.330           1800        4560           7   \n",
       "20947   98144  47.5951 -122.301           1350        3000           7   \n",
       "21246   98103  47.6611 -122.346           1650        3000          11   \n",
       "21356   98119  47.6313 -122.370           2490        4231           5   \n",
       "\n",
       "       year_sold  age_when_sold  \n",
       "1761        2014             -1  \n",
       "2685        2014             -1  \n",
       "7519        2014             -1  \n",
       "8032        2014             -1  \n",
       "14475       2014             -1  \n",
       "17084       2014             -1  \n",
       "19789       2014             -1  \n",
       "20754       2014             -1  \n",
       "20836       2014             -1  \n",
       "20947       2014             -1  \n",
       "21246       2014             -1  \n",
       "21356       2014             -1  \n",
       "\n",
       "[12 rows x 23 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"age_when_sold\"] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df[\"age_when_sold\"] >50 ].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see there are many homes that were sold at 0 years old! and even some homes that sold at -1 years old!\n",
    "\n",
    "This actually makes sense for new constructions homes. Let's assign all new construction homes to have an age of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply rule to make sure new construction homes have age of 0, and not -1\n",
    "\n",
    "df['age_when_sold'] = df['age_when_sold'].apply(lambda x: 0 if x == -1 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9      472\n",
       "8      443\n",
       "0      442\n",
       "11     431\n",
       "10     428\n",
       "      ... \n",
       "112     33\n",
       "113     28\n",
       "115     26\n",
       "81      23\n",
       "80      21\n",
       "Name: age_when_sold, Length: 116, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"age_when_sold\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   date           21597 non-null  datetime64[ns]\n",
      " 1   price          21597 non-null  float64       \n",
      " 2   bedrooms       21597 non-null  int64         \n",
      " 3   bathrooms      21597 non-null  float64       \n",
      " 4   sqft_living    21597 non-null  int64         \n",
      " 5   sqft_lot       21597 non-null  int64         \n",
      " 6   floors         21597 non-null  float64       \n",
      " 7   waterfront     19221 non-null  object        \n",
      " 8   view           21534 non-null  object        \n",
      " 9   condition      21597 non-null  object        \n",
      " 10  grade          21597 non-null  object        \n",
      " 11  sqft_above     21597 non-null  int64         \n",
      " 12  sqft_basement  21597 non-null  object        \n",
      " 13  yr_built       21597 non-null  int64         \n",
      " 14  yr_renovated   17755 non-null  float64       \n",
      " 15  zipcode        21597 non-null  int64         \n",
      " 16  lat            21597 non-null  float64       \n",
      " 17  long           21597 non-null  float64       \n",
      " 18  sqft_living15  21597 non-null  int64         \n",
      " 19  sqft_lot15     21597 non-null  int64         \n",
      " 20  month_sold     21597 non-null  int64         \n",
      " 21  year_sold      21597 non-null  int64         \n",
      " 22  age_when_sold  21597 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(6), int64(11), object(5)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2170</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1050</td>\n",
       "      <td>910.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5420</td>\n",
       "      <td>101930</td>\n",
       "      <td>3890</td>\n",
       "      <td>1530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1715</td>\n",
       "      <td>6819</td>\n",
       "      <td>1715</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1060</td>\n",
       "      <td>9711</td>\n",
       "      <td>1060</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1780</td>\n",
       "      <td>7470</td>\n",
       "      <td>1050</td>\n",
       "      <td>730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1890</td>\n",
       "      <td>6560</td>\n",
       "      <td>1890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3560</td>\n",
       "      <td>9796</td>\n",
       "      <td>1860</td>\n",
       "      <td>1700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1160</td>\n",
       "      <td>6000</td>\n",
       "      <td>860</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1430</td>\n",
       "      <td>19901</td>\n",
       "      <td>1430</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1370</td>\n",
       "      <td>9680</td>\n",
       "      <td>1370</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1810</td>\n",
       "      <td>4850</td>\n",
       "      <td>1810</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2950</td>\n",
       "      <td>5000</td>\n",
       "      <td>1980</td>\n",
       "      <td>970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1890</td>\n",
       "      <td>14040</td>\n",
       "      <td>1890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1600</td>\n",
       "      <td>4300</td>\n",
       "      <td>1600</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1200</td>\n",
       "      <td>9850</td>\n",
       "      <td>1200</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1250</td>\n",
       "      <td>9774</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1620</td>\n",
       "      <td>4980</td>\n",
       "      <td>860</td>\n",
       "      <td>760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3050</td>\n",
       "      <td>44867</td>\n",
       "      <td>2330</td>\n",
       "      <td>720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2270</td>\n",
       "      <td>6300</td>\n",
       "      <td>2270</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1070</td>\n",
       "      <td>9643</td>\n",
       "      <td>1070</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2450</td>\n",
       "      <td>6500</td>\n",
       "      <td>2450</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1710</td>\n",
       "      <td>4697</td>\n",
       "      <td>1710</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2450</td>\n",
       "      <td>2691</td>\n",
       "      <td>1750</td>\n",
       "      <td>700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1400</td>\n",
       "      <td>1581</td>\n",
       "      <td>1400</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1520</td>\n",
       "      <td>6380</td>\n",
       "      <td>790</td>\n",
       "      <td>730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2570</td>\n",
       "      <td>7173</td>\n",
       "      <td>2570</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2320</td>\n",
       "      <td>3980</td>\n",
       "      <td>2320</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1190</td>\n",
       "      <td>1265</td>\n",
       "      <td>1190</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2330</td>\n",
       "      <td>5000</td>\n",
       "      <td>1510</td>\n",
       "      <td>820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1090</td>\n",
       "      <td>3000</td>\n",
       "      <td>1090</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2060</td>\n",
       "      <td>6659</td>\n",
       "      <td>1280</td>\n",
       "      <td>780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2300</td>\n",
       "      <td>3060</td>\n",
       "      <td>1510</td>\n",
       "      <td>790.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1660</td>\n",
       "      <td>34848</td>\n",
       "      <td>930</td>\n",
       "      <td>730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2360</td>\n",
       "      <td>6000</td>\n",
       "      <td>2360</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1220</td>\n",
       "      <td>8075</td>\n",
       "      <td>890</td>\n",
       "      <td>330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2620</td>\n",
       "      <td>7553</td>\n",
       "      <td>2620</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2570</td>\n",
       "      <td>5520</td>\n",
       "      <td>2570</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4220</td>\n",
       "      <td>24186</td>\n",
       "      <td>2600</td>\n",
       "      <td>1620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3595</td>\n",
       "      <td>5639</td>\n",
       "      <td>3595</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1570</td>\n",
       "      <td>2280</td>\n",
       "      <td>1570</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1280</td>\n",
       "      <td>9656</td>\n",
       "      <td>920</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3160</td>\n",
       "      <td>13603</td>\n",
       "      <td>3160</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>990</td>\n",
       "      <td>8528</td>\n",
       "      <td>990</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2290</td>\n",
       "      <td>13416</td>\n",
       "      <td>2290</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1250</td>\n",
       "      <td>5963</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2753</td>\n",
       "      <td>65005</td>\n",
       "      <td>2165</td>\n",
       "      <td>588.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sqft_living  sqft_lot  sqft_above sqft_basement\n",
       "0          1180      5650        1180           0.0\n",
       "1          2570      7242        2170         400.0\n",
       "2           770     10000         770           0.0\n",
       "3          1960      5000        1050         910.0\n",
       "4          1680      8080        1680           0.0\n",
       "5          5420    101930        3890        1530.0\n",
       "6          1715      6819        1715             ?\n",
       "7          1060      9711        1060           0.0\n",
       "8          1780      7470        1050         730.0\n",
       "9          1890      6560        1890           0.0\n",
       "10         3560      9796        1860        1700.0\n",
       "11         1160      6000         860         300.0\n",
       "12         1430     19901        1430           0.0\n",
       "13         1370      9680        1370           0.0\n",
       "14         1810      4850        1810           0.0\n",
       "15         2950      5000        1980         970.0\n",
       "16         1890     14040        1890           0.0\n",
       "17         1600      4300        1600           0.0\n",
       "18         1200      9850        1200             ?\n",
       "19         1250      9774        1250           0.0\n",
       "20         1620      4980         860         760.0\n",
       "21         3050     44867        2330         720.0\n",
       "22         2270      6300        2270           0.0\n",
       "23         1070      9643        1070           0.0\n",
       "24         2450      6500        2450           0.0\n",
       "25         1710      4697        1710           0.0\n",
       "26         2450      2691        1750         700.0\n",
       "27         1400      1581        1400           0.0\n",
       "28         1520      6380         790         730.0\n",
       "29         2570      7173        2570           0.0\n",
       "30         2320      3980        2320           0.0\n",
       "31         1190      1265        1190           0.0\n",
       "32         2330      5000        1510         820.0\n",
       "33         1090      3000        1090           0.0\n",
       "34         2060      6659        1280         780.0\n",
       "35         2300      3060        1510         790.0\n",
       "36         1660     34848         930         730.0\n",
       "37         2360      6000        2360           0.0\n",
       "38         1220      8075         890         330.0\n",
       "39         2620      7553        2620           0.0\n",
       "40         2570      5520        2570           0.0\n",
       "41         4220     24186        2600        1620.0\n",
       "42         3595      5639        3595             ?\n",
       "43         1570      2280        1570           0.0\n",
       "44         1280      9656         920         360.0\n",
       "45         3160     13603        3160           0.0\n",
       "46          990      8528         990           0.0\n",
       "47         2290     13416        2290           0.0\n",
       "48         1250      5963        1250           0.0\n",
       "49         2753     65005        2165         588.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['sqft_living','sqft_lot','sqft_above','sqft_basement']].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see some odd values for sqft_basement. We can see the pattern in the data and safely assume that :\n",
    "\n",
    ">sqft_living = sqft_above + sqft_basement\n",
    "\n",
    "Let's take a closer look at the rows with bad data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1715</td>\n",
       "      <td>6819</td>\n",
       "      <td>1715</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1200</td>\n",
       "      <td>9850</td>\n",
       "      <td>1200</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3595</td>\n",
       "      <td>5639</td>\n",
       "      <td>3595</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>3450</td>\n",
       "      <td>39683</td>\n",
       "      <td>3450</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1540</td>\n",
       "      <td>12600</td>\n",
       "      <td>1160</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21442</th>\n",
       "      <td>2360</td>\n",
       "      <td>5000</td>\n",
       "      <td>1390</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21447</th>\n",
       "      <td>2330</td>\n",
       "      <td>4907</td>\n",
       "      <td>2330</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21473</th>\n",
       "      <td>980</td>\n",
       "      <td>1010</td>\n",
       "      <td>980</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21519</th>\n",
       "      <td>2380</td>\n",
       "      <td>5737</td>\n",
       "      <td>2380</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21581</th>\n",
       "      <td>3410</td>\n",
       "      <td>10125</td>\n",
       "      <td>3410</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>454 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sqft_living  sqft_lot  sqft_above sqft_basement\n",
       "6             1715      6819        1715             ?\n",
       "18            1200      9850        1200             ?\n",
       "42            3595      5639        3595             ?\n",
       "79            3450     39683        3450             ?\n",
       "112           1540     12600        1160             ?\n",
       "...            ...       ...         ...           ...\n",
       "21442         2360      5000        1390             ?\n",
       "21447         2330      4907        2330             ?\n",
       "21473          980      1010         980             ?\n",
       "21519         2380      5737        2380             ?\n",
       "21581         3410     10125        3410             ?\n",
       "\n",
       "[454 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['sqft_basement'] == '?'][['sqft_living','sqft_lot','sqft_above','sqft_basement']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0       12826\n",
       "?           454\n",
       "600.0       217\n",
       "500.0       209\n",
       "700.0       208\n",
       "          ...  \n",
       "1920.0        1\n",
       "3480.0        1\n",
       "2730.0        1\n",
       "2720.0        1\n",
       "248.0         1\n",
       "Name: sqft_basement, Length: 304, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sqft_basement'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0       0.593879\n",
       "?         0.021021\n",
       "600.0     0.010048\n",
       "500.0     0.009677\n",
       "700.0     0.009631\n",
       "            ...   \n",
       "1920.0    0.000046\n",
       "3480.0    0.000046\n",
       "2730.0    0.000046\n",
       "2720.0    0.000046\n",
       "248.0     0.000046\n",
       "Name: sqft_basement, Length: 304, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sqft_basement'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing that the **sqft_living** and **sqft_above** columns are clean for every row, we can easily recalculate (and thus whole-sale clean) the sqft_basement column in one line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalculate sqft basement using formula above\n",
    "\n",
    "df['sqft_basement'] = df['sqft_living'] - df['sqft_above'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5420</td>\n",
       "      <td>101930</td>\n",
       "      <td>3890</td>\n",
       "      <td>1530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1715</td>\n",
       "      <td>6819</td>\n",
       "      <td>1715</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1060</td>\n",
       "      <td>9711</td>\n",
       "      <td>1060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1780</td>\n",
       "      <td>7470</td>\n",
       "      <td>1050</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1890</td>\n",
       "      <td>6560</td>\n",
       "      <td>1890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sqft_living  sqft_lot  sqft_above  sqft_basement\n",
       "0         1180      5650        1180              0\n",
       "1         2570      7242        2170            400\n",
       "2          770     10000         770              0\n",
       "3         1960      5000        1050            910\n",
       "4         1680      8080        1680              0\n",
       "5         5420    101930        3890           1530\n",
       "6         1715      6819        1715              0\n",
       "7         1060      9711        1060              0\n",
       "8         1780      7470        1050            730\n",
       "9         1890      6560        1890              0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['sqft_living','sqft_lot','sqft_above','sqft_basement']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.607029\n",
       "600    0.010233\n",
       "700    0.010094\n",
       "500    0.009909\n",
       "800    0.009538\n",
       "         ...   \n",
       "518    0.000046\n",
       "374    0.000046\n",
       "784    0.000046\n",
       "906    0.000046\n",
       "248    0.000046\n",
       "Name: sqft_basement, Length: 306, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sqft_basement'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per the normalized value counts, we see that 60% of the data has no basement. Let's create a categorical column indentifying if a home had a basement or not at time of sale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define new function and apply it to create new column for if a home has a basement\n",
    "\n",
    "def basement(number):\n",
    "    if number > 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['has_basement']  = df['sqft_basement'].apply(basement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13110\n",
       "1     8487\n",
       "Name: has_basement, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['has_basement'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      13110\n",
       "600      221\n",
       "700      218\n",
       "500      214\n",
       "800      206\n",
       "       ...  \n",
       "518        1\n",
       "374        1\n",
       "784        1\n",
       "906        1\n",
       "248        1\n",
       "Name: sqft_basement, Length: 306, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sqft_basement'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value counts match so we know we did it correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 24 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   date           21597 non-null  datetime64[ns]\n",
      " 1   price          21597 non-null  float64       \n",
      " 2   bedrooms       21597 non-null  int64         \n",
      " 3   bathrooms      21597 non-null  float64       \n",
      " 4   sqft_living    21597 non-null  int64         \n",
      " 5   sqft_lot       21597 non-null  int64         \n",
      " 6   floors         21597 non-null  float64       \n",
      " 7   waterfront     19221 non-null  object        \n",
      " 8   view           21534 non-null  object        \n",
      " 9   condition      21597 non-null  object        \n",
      " 10  grade          21597 non-null  object        \n",
      " 11  sqft_above     21597 non-null  int64         \n",
      " 12  sqft_basement  21597 non-null  int64         \n",
      " 13  yr_built       21597 non-null  int64         \n",
      " 14  yr_renovated   17755 non-null  float64       \n",
      " 15  zipcode        21597 non-null  int64         \n",
      " 16  lat            21597 non-null  float64       \n",
      " 17  long           21597 non-null  float64       \n",
      " 18  sqft_living15  21597 non-null  int64         \n",
      " 19  sqft_lot15     21597 non-null  int64         \n",
      " 20  month_sold     21597 non-null  int64         \n",
      " 21  year_sold      21597 non-null  int64         \n",
      " 22  age_when_sold  21597 non-null  int64         \n",
      " 23  has_basement   21597 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(6), int64(13), object(4)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO     19075\n",
       "YES      146\n",
       "Name: waterfront, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['waterfront'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2376"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check null values\n",
    "\n",
    "df['waterfront'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most homes are overwhelming **NO** for **waterfront**. So it's safe to fill in the missing values with NO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO     21451\n",
       "YES      146\n",
       "Name: waterfront, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill in NO for missing waterfront rows\n",
    "\n",
    "df['waterfront'].fillna('NO', inplace=True)\n",
    "df['waterfront'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    21451\n",
       "1      146\n",
       "Name: waterfront, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to 1's and 0's as we know we will do linear regression later\n",
    "\n",
    "df['waterfront'] = df['waterfront'].map(lambda x: 1 if x == 'YES' else 0)\n",
    "df['waterfront'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yr_renovated'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yr_renovated'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yr_renovated'].value_counts(normalize=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yr_renovated'].fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yr_renovated'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yr_renovated'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reno(year):\n",
    "    if year > 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['recent_reno']  = df['yr_renovated'].apply(reno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['recent_reno'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-(744/21597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['recent_reno'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['date', 'yr_built','yr_renovated' ], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"grade\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"grade\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"condition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['condition'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"condition\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_key = {'Poor':1.0 , 'Fair':2.0 , 'Average':3.0 , 'Good':4.0 , 'Very Good':5.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grade_key = {'3 Poor':0.0,\n",
    "#              '4 Low':1.0,\n",
    "#              '5 Fair':2.0,\n",
    "#              '6 Low Average':3.0,\n",
    "#              '7 Average': 4.0,\n",
    "#              '8 Good':5.0,\n",
    "#              '9 Better':6.0,\n",
    "#              '10 Very Good':7.0,\n",
    "#              '11 Excellent':8.0,\n",
    "#              '12 Luxury': 9.0,\n",
    "#              '13 Mansion':10.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_key = {'3 Poor':3.0,\n",
    "             '4 Low':4.0,\n",
    "             '5 Fair':5.0,\n",
    "             '6 Low Average':6.0,\n",
    "             '7 Average': 7.0,\n",
    "             '8 Good':8.0,\n",
    "             '9 Better':9.0,\n",
    "             '10 Very Good':10.0,\n",
    "             '11 Excellent':11.0,\n",
    "             '12 Luxury': 12.0,\n",
    "             '13 Mansion':13.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_key = {'NONE':1.0 , 'AVERAGE':2.0 , 'GOOD':3.0 , 'FAIR':4.0 , 'EXCELLENT':5.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['condition'] = df['condition'].replace(condition_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['grade'] = df['grade'].replace(grade_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['view'] = df['view'].replace(view_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('year_sold', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['view'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['view'].fillna(1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['view'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view(number):\n",
    "    if number > 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['has_view']  = df['view'].apply(view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('lat', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('long', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['condition'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Z Score to remove outliers\n",
    "\n",
    "The code below produces a heatmap showing the correlations between all of the numeric values in our training data. The x and y axis labels indicate the pair of values that are being compared, and then the color and the number are both representing the correlation. Color is used here to make it easier to find the largest/smallest numbers — you could perform this analysis with just `train.corr()` if all you wanted was the correlation values.\n",
    "\n",
    "The very left column of the plot is the most important, since it shows correlations between the target (listing price) and other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize  = [30, 20]); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical = ['price', 'sqft_living','sqft_living15', 'sqft_lot','sqft_lot15','sqft_above', 'sqft_basement','lat','long','age_when_sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['price', 'sqft_living','sqft_living15', 'sqft_lot','sqft_lot15','sqft_above', 'sqft_basement','age_when_sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kindaboth = ['bedrooms', 'bathrooms', 'floors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['waterfront', 'view','condition','grade','month_sold','recent_reno','has_view','zipcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.abs(stats.zscore(df[numerical+kindaboth]))\n",
    "z.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df[(z<6).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[(z<3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df[(z<2).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.hist(figsize  = [30, 20]); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Regresssion Modeling\n",
    "### Baseline Model - Most Correlated Feature\n",
    "\n",
    "The code below produces a heatmap showing the correlations between all of the numeric values in our training data. The x and y axis labels indicate the pair of values that are being compared, and then the color and the number are both representing the correlation. Color is used here to make it easier to find the largest/smallest numbers — you could perform this analysis with just `train.corr()` if all you wanted was the correlation values.\n",
    "\n",
    "The very left column of the plot is the most important, since it shows correlations between the target (listing price) and other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "#sns.heatmap(df.corr(), annot=True, square=True, cmap= \"Blues\", mask=np.triu(np.ones_like(df.corr(), dtype=bool)),)\n",
    "sns.heatmap(df.corr(), annot=True, square=True, cmap= \"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the plot above, which feature is most strongly correlated with the target (`listing_price`)? In other words, which feature has the strongest positive or negative correlation — the correlation with the greatest magnitude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "most_correlated = \"grade\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Make sure you run the cell above before proceeding.)\n",
    "\n",
    "Let's create a scatter plot of that feature vs. listing price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(df[most_correlated], df['price'], alpha=0.5)\n",
    "ax.set_xlabel(most_correlated)\n",
    "ax.set_ylabel(\"price\")\n",
    "ax.set_title(\"Most Correlated Feature vs. Listing Price\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming you correctly identified `piece_count` (the number of pieces in the LEGO set) as the most correlated feature, you should have a scatter plot that shows a fairly clear linear relationship between that feature and the target. It looks like we are ready to proceed with making our baseline model without any additional transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "Now, we'll build a linear regression model using just that feature, which will serve as our baseline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "splitter = ShuffleSplit(n_splits=3, test_size=0.25, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_scores = cross_validate(\n",
    "    estimator=baseline_model,\n",
    "    X=df[[most_correlated]],\n",
    "    y=df['price'],\n",
    "    return_train_score=True,\n",
    "    cv=splitter\n",
    ")\n",
    "\n",
    "baseline_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train score:     \", baseline_scores[\"train_score\"].mean())\n",
    "print(\"Validation score:\", baseline_scores[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we evaluate the model using `cross_validate` and `ShuffleSplit`, which essentially means that we perform 3 separate train-test splits within our `X_train` and `y_train`, then we find both the train and the test scores for each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret these scores below. What are we measuring? What can we learn from this?\n",
    "\n",
    "**Hint:** when you use `cross_validate`, it uses the `.score` method of the estimator by default. See [documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.score) for that method of `LinearRegression`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary style=\"cursor: pointer\">Solution (click to reveal)</summary>\n",
    "    <p>Because we are using the <code>.score</code> method of <code>LinearRegression</code>, these are r-squared scores. That means that each of them represents the amount of variance of the target (listing price) that is explained by the model's features (currently just the number of pieces) and parameters (intercept value and coefficient values for the features)</p>\n",
    "    <p>In general this seems like a fairly strong model already. It is getting nearly identical performance on training subsets compared to the validation subsets, explaining around 80% of the variance both times</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now that we have established a baseline, it's time to move on to more complex models.\n",
    "\n",
    "### 2nd Model - All Features\n",
    "\n",
    "One thing that you will almost always need to do in a modeling process is remove non-numeric data prior to modeling. While you could apply more-advanced techniques such as one-hot encoding or NLP in order to convert non-numeric columns into numbers, this time just create a dataframe `X_train_numeric` that is a copy of `X_train` that only contains numeric columns.\n",
    "\n",
    "You can look at the `df.info()` printout above to do this manually, or there is a handy `.select_dtypes` method ([documentation here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.select_dtypes.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot_data = df.drop(\"price\",axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, nrows=7, figsize=(15, 20))\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "for index, col in enumerate(scatterplot_data.columns):\n",
    "    ax = axes[index//3][index%3]\n",
    "    ax.scatter(df[col], df[\"price\"], alpha=0.2)\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel(\"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_model = LinearRegression()\n",
    "\n",
    "second_model_scores = cross_validate(\n",
    "    estimator=second_model,\n",
    "    X=df.drop(\"price\",axis=1),\n",
    "    y=df['price'],\n",
    "    return_train_score=True,\n",
    "    cv=splitter\n",
    ")\n",
    "\n",
    "print(\"Current Model - Linear Regression with all Features\")\n",
    "print(\"Train score:     \", second_model_scores[\"train_score\"].mean())\n",
    "print(\"Validation score:\", second_model_scores[\"test_score\"].mean())\n",
    "print()\n",
    "print(\"Baseline Model - Linear Regression with only Most Correlated Feature\")\n",
    "print(\"Train score:     \", baseline_scores[\"train_score\"].mean())\n",
    "print(\"Validation score:\", baseline_scores[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.OLS(df['price'], sm.add_constant(df.drop(\"price\",axis=1))).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigating Multicollinearity\n",
    "\n",
    "This potentially indicates that our model is performing poorly because these features violate the independence assumption (i.e. there is strong multicollinearity). In other words, maybe the minimum age, maximum age, and difficulty level are not really providing different information than the number of pieces in the LEGO set, and instead are just adding noise. Then the model is using that noise to get a slightly better score on the training data, but but a worse score on the validation data.\n",
    "\n",
    "While `LinearRegression` from scikit-learn has a lot of nice functionality for working with a predictive framing (e.g. compatibility with the `cross_validate` function), it doesn't have anything built in to detect strong multicollinearity. Fortunately the same linear regression model is also available from StatsModels ([documentation here](https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLS.html)), where it is called `OLS` (for \"ordinary least squares\"). Models in StatsModels, including `OLS`, are not really designed for predictive model validation, but they do give us a lot more statistical information.\n",
    "\n",
    "In the cell below, we use StatsModels to fit and evaluate a linear regression model on the same features used in the second model. Note that we will only see one r-squared value (not train and validation r-squared values) because it is using the full `X_train` dataset instead of using cross-validation.\n",
    "\n",
    "A condition number of 10-30 indicates multicollinearity, and a condition number above 30 indicates strong multicollinearity. This print-out shows a condition number of `2.85e+03`, i.e. 2770, which is well above 30.\n",
    "\n",
    "In a predictive context (we are currently trying to build a model to assign prices to future LEGO sets, not a model primarily intended for understanding the relationship between prices and attributes of past LEGO sets), we do not *always* need to be worried when we identify strong multicollinearity. Sometimes there are features that are highly collinear but they also are individually communicating useful information to the model. In this case, however, it seems like strong multicollinearity might be what is causing our second model to have worse performance than the first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(df.corr()) > 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save absolute value of correlation matrix as a data frame\n",
    "# converts all values to absolute value\n",
    "# stacks the row:column pairs into a multindex\n",
    "# reset the index to set the multindex to seperate columns\n",
    "# sort values. 0 is the column automatically generated by the stacking\n",
    "\n",
    "dfcorr=df.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "\n",
    "# zip the variable name columns (Which were only named level_0 and level_1 by default) in a new column named \"pairs\"\n",
    "dfcorr['pairs'] = list(zip(dfcorr.level_0, dfcorr.level_1))\n",
    "\n",
    "# set index to pairs\n",
    "dfcorr.set_index(['pairs'], inplace = True)\n",
    "\n",
    "#d rop level columns\n",
    "dfcorr.drop(columns=['level_1', 'level_0'], inplace = True)\n",
    "\n",
    "# rename correlation column as cc rather than 0\n",
    "dfcorr.columns = ['cc']\n",
    "\n",
    "# drop duplicates. This could be dangerous if you have variables perfectly correlated with variables other than themselves.\n",
    "# for the sake of exercise, kept it in.\n",
    "dfcorr.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcorr[(dfcorr.cc>.75) & (dfcorr.cc <1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(df.corr()['price']).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# between sqft living and sq ft above, we want to get rid of sq ft above as it is less correlated to price\n",
    "# also sq ft above can be recalculated\n",
    "\n",
    "# between lot15 and lot, get rid of lot15\n",
    "\n",
    "#smaller abs value correlation to price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(['sqft_above','sqft_lot15'], axis=1)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['sqft_above','sqft_lot15','sqft_basement','view'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(['sqft_above','sqft_lot15','sqft_basement','has_view'], axis=1)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(['sqft_living'], axis=1)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.OLS(y, sm.add_constant(df.drop(\"price\",axis=1))).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code checks that your answer was correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at scatter plots of all numeric features compared to the target (skipping `piece_count` since we already looked at that earlier):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd Model - One Hot Encoding Categorical Features\n",
    "\n",
    "Ok, now all of the remaining features can technically go into a model with scikit-learn. But do they make sense?\n",
    "\n",
    "Some reasons you might not want to include a given numeric column include:\n",
    "\n",
    "1. The column represents a unique identifier, not an actual numeric feature\n",
    "2. The column is something that will not be available when making future predictions\n",
    "\n",
    "Recall that the business purpose here is creating an algorithm to set the price for a newly-released LEGO set. Which columns should we drop because of the issues above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <details>\n",
    "    <summary style=\"cursor: pointer\">Solution (click to reveal)</summary>\n",
    "    <p>The first issue aligns with the first feature we have, <code>prod_id</code></p>\n",
    "    <p>While it is possible that there is some useful information encoded in that number, it seems like it is not really a numeric feature in the traditional sense</p>\n",
    "    <p>The scatter plot supports this idea, since it shows almost all prices being represented by a narrow range of ID values</p>\n",
    "    <p>The second issue aligns with <code>num_reviews</code> and <code>star_rating</code>. Although these might be useful features in some modeling context, they are not useful for this algorithm because we won't know the number of reviews or the star rating until after the LEGO set is released.</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a variable `X_train_second_model`, which is a copy of `X_train_numeric` where those irrelevant columns have been removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical = ['sqft_living15', 'sqft_lot','sqft_lot15','sqft_above', 'sqft_basement','lat','long','age_when_sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical = ['sqft_living15', 'sqft_lot','sqft_living', 'sqft_basement','age_when_sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['sqft_living15', 'sqft_lot','sqft_living','age_when_sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical = ['sqft_living15', 'sqft_lot','sqft_lot15','sqft_above', 'sqft_basement','age_when_sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kindaboth = ['bedrooms', 'bathrooms', 'floors','condition','grade','view']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kindaboth = ['bedrooms', 'bathrooms', 'floors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kindaboth = ['bedrooms', 'bathrooms', 'floors', 'condition', 'grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kindaboth = ['bedrooms', 'bathrooms', 'floors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kindaboth = ['bedrooms', 'bathrooms', 'floors', 'grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical = ['waterfront', 'month_sold','has_basement','recent_reno','zipcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical = ['waterfront', 'view', 'condition', 'grade', 'month_sold','recent_reno','zipcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['waterfront', 'has_view','month_sold','has_basement','recent_reno','zipcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical = ['waterfront', 'has_view','month_sold','has_basement','recent_reno']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical = ['waterfront', 'view','month_sold','has_basement','recent_reno','zipcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical = ['waterfront','view','condition','grade','month_sold','has_basement','recent_reno','zipcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical = ['waterfront', 'has_view','condition', 'month_sold','has_basement','recent_reno','zipcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical = ['waterfront', 'has_view', 'condition', 'grade', 'month_sold','has_basement','recent_reno','zipcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in (kindaboth+categorical):\n",
    "    ax, figure = plt.subplots(1,1,figsize=(30,20))\n",
    "    sns.boxplot(x=variable, y='price', data=df)\n",
    "    plt.title(\"{} vs. price\".format(variable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('zipcode')['price'].median().sort_values(ascending=False).head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('zipcode')['price'].mean().sort_values(ascending=False).head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## interesting, lets see where those 4 zip codes end up in our final model later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[categorical].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories = pd.DataFrame()\n",
    "\n",
    "for cat in categorical:\n",
    "    df_categories[cat]=df2[cat].astype('category')\n",
    "    df_dummy = pd.get_dummies(df_categories[cat], prefix=cat, drop_first=True) \n",
    "    df_categories = df_categories.join(df_dummy)\n",
    "    df_categories.drop(labels=cat, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfohe= df2.drop(categorical, axis=1)\n",
    "dfohe = pd.concat([dfohe, df_categories], axis=1)\n",
    "dfohe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfohe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.OLS(dfohe['price'], sm.add_constant(dfohe.drop(\"price\",axis=1))).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_model = LinearRegression()\n",
    "\n",
    "third_model_scores = cross_validate(\n",
    "    estimator=third_model,\n",
    "    X=dfohe.drop(\"price\",axis=1),\n",
    "    # y=df2logprice,\n",
    "    y=dfohe['price'],\n",
    "    return_train_score=True,\n",
    "    cv=splitter\n",
    ")\n",
    "\n",
    "print(\"Current Model (OHE of categorical features only)\")\n",
    "print(\"Train score:     \", third_model_scores[\"train_score\"].mean())\n",
    "print(\"Validation score:\", third_model_scores[\"test_score\"].mean())\n",
    "print()\n",
    "\n",
    "# print(\"Second Second Model (log transform price)\")\n",
    "# print(\"Train score:     \", second2_model_scores[\"train_score\"].mean())\n",
    "# print(\"Validation score:\", second2_model_scores[\"test_score\"].mean())\n",
    "# print()\n",
    "\n",
    "print(\"Second Model (using all features)\")\n",
    "print(\"Train score:     \", second_model_scores[\"train_score\"].mean())\n",
    "print(\"Validation score:\", second_model_scores[\"test_score\"].mean())\n",
    "print()\n",
    "\n",
    "print(\"Baseline Model (just using most correlated feature)\")\n",
    "print(\"Train score:     \", baseline_scores[\"train_score\"].mean())\n",
    "print(\"Validation score:\", baseline_scores[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4th Model - Log Transform Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfohe[numerical+kindaboth+['price']].hist(figsize = (30,20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trylog = ['sqft_living15', 'sqft_lot','sqft_lot15', 'sqft_above', 'sqft_basement','price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trylog = ['sqft_living15', 'sqft_lot','sqft_lot15', 'sqft_above','sqft_basement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trylog = ['sqft_living15', 'sqft_lot','sqft_living','sqft_basement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trylog = ['sqft_living15', 'sqft_lot','sqft_living','sqft_basement','price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trylog = ['sqft_living15', 'sqft_lot','sqft_living']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trylog = ['sqft_living15', 'sqft_lot','sqft_living','price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trylog = ['sqft_lot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trylog = numerical + kindaboth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trylog = numerical + kindaboth + [\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trylog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfohelog = dfohe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feat in trylog:\n",
    "#     dfohelog[feat] = dfohelog[feat].map(lambda x: np.log1p(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in trylog:\n",
    "    dfohelog[feat] = dfohelog[feat].map(lambda x: np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfohelog[numerical+kindaboth+['price']].hist(figsize = (30,20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLS = dfohelog['price']\n",
    "XOLS = dfohelog.drop(\"price\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.OLS(YOLS, sm.add_constant(XOLS)).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_model = LinearRegression()\n",
    "\n",
    "fourth_model_scores = cross_validate(\n",
    "    estimator=fourth_model,\n",
    "    X=dfohelog.drop(\"price\",axis=1),\n",
    "    # y=df2logprice,\n",
    "    y=dfohelog['price'],\n",
    "    return_train_score=True,\n",
    "    cv=splitter\n",
    ")\n",
    "print(\"Current Model (log transform sq ft numerical features and price)\")\n",
    "print(\"Train score:     \", fourth_model_scores[\"train_score\"].mean())\n",
    "print(\"Validation score:\", fourth_model_scores[\"test_score\"].mean())\n",
    "print()\n",
    "\n",
    "print(\"Third Model (OHE of categorical features only)\")\n",
    "print(\"Train score:     \", third_model_scores[\"train_score\"].mean())\n",
    "print(\"Validation score:\", third_model_scores[\"test_score\"].mean())\n",
    "print()\n",
    "\n",
    "# print(\"Second Second Model (log transform price)\")\n",
    "# print(\"Train score:     \", second2_model_scores[\"train_score\"].mean())\n",
    "# print(\"Validation score:\", second2_model_scores[\"test_score\"].mean())\n",
    "# print()\n",
    "\n",
    "print(\"Second Model (using all features)\")\n",
    "print(\"Train score:     \", second_model_scores[\"train_score\"].mean())\n",
    "print(\"Validation score:\", second_model_scores[\"test_score\"].mean())\n",
    "print()\n",
    "\n",
    "print(\"Baseline Model (just using most correlated feature\")\n",
    "print(\"Train score:     \", baseline_scores[\"train_score\"].mean())\n",
    "print(\"Validation score:\", baseline_scores[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret these results. Did our second model perform better than the baseline? Any ideas about why or why not?\n",
    "\n",
    "**Hint:** because the purpose of this model is to set future prices that have not been determined yet, the most important metric for evaluating model performance is the validation score, not the train score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate text\n",
    "\"\"\"\n",
    "I think it got worse.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary style=\"cursor: pointer\">Solution (click to reveal)</summary>\n",
    "    <p>Our second model got slightly better scores on the training data, but worse scores on the validation data. This means that it is a worse model overall, since what we care about is the ability to generate prices for future LEGO sets, not the ability to fit well to the known LEGO sets' features</p>\n",
    "    <p>It seems like adding in these other features is actually just causing overfitting, rather than improving the model's ability to understand the underlying patterns in the data</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5th Model - Select Best Combination of Features\n",
    "\n",
    "As you likely noted above, adding all relevant numeric features did not actually improve the model performance. Instead, it led to overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting Features Based on p-values\n",
    "\n",
    "Given that we suspect our model's issues are related to multicollinearity, let's try to narrow down those features. In this case, let's use the p-values assigned to the coefficients of the model.\n",
    "\n",
    "Looking at the model summary above, ***which features are statistically significant, with p-values below 0.05***? (P-values are labeled **P>|t|** in a StatsModels summary.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate text\n",
    "\"\"\"\n",
    "piece count and min age\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary style=\"cursor: pointer\">Solution (click to reveal)</summary>\n",
    "    <p><code>const</code> (the intercept), <code>piece_count</code>, and <code>min_age</code></p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important note:** There are many limitations to using coefficient p-values to select features. See [this StackExchange answer](https://stats.stackexchange.com/a/291239) with examples in R for more details. The suggested alternative in that answer, `glmnet`, is a form of *regularization*, which you will learn about later. Another related technique is *dimensionality reduction*, which will also be covered later. However for now you can proceed using just the p-values technique until the more-advanced techniques have been covered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, create a list `significant_features` that contains the names of the columns whose features have statistically significant coefficient p-values. You should not include `\"const\"` in that list because `LinearRegression` from scikit-learn automatically adds a constant term and there is no column of `X_train` called `\"const\"`.\n",
    "\n",
    "(You do not need to extract this information programmatically, just write them out like `\"column_name_1\", \"column_name_2\"` etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build a model using those significant features only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret the results below. What happened when we removed the features with high p-values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate text\n",
    "\"\"\"\n",
    "Still looks basically the same performance to me\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary style=\"cursor: pointer\">Solution (click to reveal)</summary>\n",
    "    <p>Removing those features led to the best model so far, although the scores are very similar to the baseline</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting Features with `sklearn.feature_selection`\n",
    "\n",
    "Let's try a different approach. Scikit-learn has a submodule called `feature_selection` that includes tools to help reduce the feature set.\n",
    "\n",
    "We'll use `RFECV` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV)). \"RFE\" stands for \"recursive feature elimination\", meaning that it repeatedly scores the model, finds and removes the feature with the lowest \"importance\", then scores the model again. If the new score is better than the previous score, it continues removing features until the minimum is reached. \"CV\" stands for \"cross validation\" here, and we can use the same splitter we have been using to test our data so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Min/Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(dfohelog.corr()['price']).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toscale = [numerical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toscale = [numerical+kindaboth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toscale = [numerical,'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toscale = ['age_when_sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfoheminmax = dfohelog.copy()\n",
    "\n",
    "for feature in toscale:\n",
    "    d_min = dfoheminmax[feature].min()\n",
    "    d_max = dfoheminmax[feature].max()\n",
    "    dfoheminmax[feature] = (dfoheminmax[feature] - d_min) / (d_max - d_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfoheminmax.describe().transpose().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(dfoheminmax.corr()['price']).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfoheminmax[numerical+kindaboth+['price']].hist(figsize = (30,20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLS = dfoheminmax['price']\n",
    "XOLS = dfoheminmax.drop(\"price\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.OLS(YOLS, sm.add_constant(XOLS)).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yscaled = dfoheminmax['price']\n",
    "Xscaled = dfoheminmax.drop(\"price\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "model_for_RFECV = LinearRegression()\n",
    "\n",
    "# Instantiate and fit the selector\n",
    "selector = RFECV(model_for_RFECV, cv=splitter)\n",
    "selector.fit(Xscaled,Yscaled)\n",
    "\n",
    "# Print the results\n",
    "print(\"Was the column selected?\")\n",
    "for index, col in enumerate(Xscaled.columns):\n",
    "    print(f\"{col}: {selector.support_[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xscaled.columns[selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xscaled.columns[selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFECV_features = Xscaled.columns[selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFECV_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.OLS(Yscaled, sm.add_constant(Xscaled[RFECV_features])).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifth_model = LinearRegression()\n",
    "\n",
    "fifth_model_scores = cross_validate(\n",
    "    estimator=fifth_model,\n",
    "    X=Xscaled[RFECV_features],\n",
    "    y=Yscaled,\n",
    "    return_train_score=True,\n",
    "    cv=splitter\n",
    ")\n",
    "\n",
    "print(\"Current Mdoel (Recursive Feature Elimination after Min Max Scaling)\")\n",
    "print(\"Train score:     \", fifth_model_scores[\"train_score\"].mean())\n",
    "print(\"Validation score:\", fifth_model_scores[\"test_score\"].mean())\n",
    "print()\n",
    "\n",
    "print(\"Fourth Model (log transform sq ft numerical features and price)\")\n",
    "print(\"Train score:     \", fourth_model_scores[\"train_score\"].mean())\n",
    "print(\"Validation score:\", fourth_model_scores[\"test_score\"].mean())\n",
    "print()\n",
    "\n",
    "print(\"Third Model (OHE of categorical features only)\")\n",
    "print(\"Train score:     \", third_model_scores[\"train_score\"].mean())\n",
    "print(\"Validation score:\", third_model_scores[\"test_score\"].mean())\n",
    "print()\n",
    "\n",
    "# print(\"Second Second Model (log transform price)\")\n",
    "# print(\"Train score:     \", second2_model_scores[\"train_score\"].mean())\n",
    "# print(\"Validation score:\", second2_model_scores[\"test_score\"].mean())\n",
    "# print()\n",
    "\n",
    "print(\"Second Model (using all features)\")\n",
    "print(\"Train score:     \", second_model_scores[\"train_score\"].mean())\n",
    "print(\"Validation score:\", second_model_scores[\"test_score\"].mean())\n",
    "print()\n",
    "\n",
    "print(\"Baseline Model (just using most correlated feature\")\n",
    "print(\"Train score:     \", baseline_scores[\"train_score\"].mean())\n",
    "print(\"Validation score:\", baseline_scores[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. So, this algorithm is saying that our baseline model, with `piece_count` as the only feature, is the best one it could find.\n",
    "\n",
    "However, note that this is based on the \"importances\" of the features, which means the coefficients in the context of a linear regression. It is possible that we can still get a better model by including multiple features, if we try removing columns using a different strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret the table above. It shows both training and validation scores for `piece_count` as well as all combinations of 0, 1, 2, or 3 other features.\n",
    "\n",
    "Which features make the best model? Which make the worst? How does this align with the previous discussion of multicollinearity? And how much does feature selection seem to matter in general for this dataset + model algorithm, once we have identified the most correlated feature for the baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate text\n",
    "\"\"\"\n",
    "in my opinion, the differences seem negiligible as long as piece count is the main feature for the model. row 6 has best val score. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary style=\"cursor: pointer\">Solution (click to reveal)</summary>\n",
    "    <p>The best model uses <code>piece_count</code>, <code>max_age</code>, and <code>difficulty_level</code>. It has a validation score of 0.781578</p>\n",
    "    <p>The worst model uses <code>piece_count</code>, <code>min_age</code>, and <code>max_age</code>. It has a validation score of 0.751768</p>\n",
    "    <p>This makes sense if we think that <code>min_age</code> and <code>max_age</code> are mostly providing the same information, and that the difference is mainly noise (leading to overfitting), that the best model would only have one of them</p>\n",
    "    <p>Overall, feature selection does not seem to matter very much for this dataset + linear regression. So long as we use our most correlated feature (<code>piece_count</code>), the validation score doesn't change very much, regardless of which other features are included.</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regression Results\n",
    "\n",
    "### Final Predictive Model\n",
    "\n",
    "In the cell below, create a list `best_features` which contains the names of the best model features based on the findings of the previous step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate code\n",
    "# best_features = [\"piece_count\", \"max_age\", \"difficulty_level\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we prepare the data for modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run this cell without changes\n",
    "# X_train_final = X_train[best_features]\n",
    "# X_test_final = X_test[best_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, instantiate a `LinearRegression` model called `final_model`, then fit it on the training data and score it on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace None with appropriate code\n",
    "\n",
    "# final_model = LinearRegression()\n",
    "\n",
    "# # Fit the model on X_train_final and y_train\n",
    "# final_model.fit(X_train_final, y_train)\n",
    "\n",
    "# # Score the model on X_test_final and y_test\n",
    "# # (use the built-in .score method)\n",
    "# final_model.score( X_test_final, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(Xscaled[RFECV_features], Yscaled, shuffle=True, test_size=0.25, random_state=10)\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "y_train_preds = linreg.predict(X_train)\n",
    "y_val_preds = linreg.predict(X_val)\n",
    "y_pred = linreg.predict(Xscaled[RFECV_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.scatterplot(x=y_train_preds, y=y_train)\n",
    "\n",
    "# sns.lineplot(x=y_train_preds, y=y_train_preds, color='red')\n",
    "\n",
    "# plt.title('Actual vs. Predicted (Training Set)')\n",
    "# plt.xlabel('Predicted (log(1+$))')\n",
    "# plt.ylabel('Actual (log(1+$))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_val_preds = linreg.predict(X_val)\n",
    "\n",
    "\n",
    "# sns.scatterplot(x=y_val_preds, y=y_val)\n",
    "# sns.lineplot(x=y_val_preds, y=y_val_preds, color='red')\n",
    "# plt.title('Actual vs. Predicted (Validation Set)')\n",
    "# plt.xlabel('Predicted (log(1+$))')\n",
    "# plt.ylabel('Actual (log(1+$))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_int = sm.add_constant(Xscaled[RFECV_features])\n",
    "model = sm.OLS(Yscaled.astype(float), X_int.astype(float)).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(30, 20))\n",
    "sns.histplot(Yscaled, label='Actual', color='blue',bins='auto')\n",
    "sns.histplot(y_pred, label='Predict', color='red',bins='auto')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(30, 20))\n",
    "# sns.histplot(Yscaled, label='Actual', color='blue', binwidth=.1)\n",
    "# sns.histplot(y_pred, label='Predict', color='red', binwidth=.1)\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm.graphics.qqplot(model.resid, line='45', fit=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(Yscaled, model.resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 98039    1735000.0\n",
    "# 98004    1100000.0\n",
    "# 98040     989950.0\n",
    "# 98112     900000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.params.sort_values(ascending=False).round(3).head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.params.sort_values(ascending=True).round(3).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run this cell without changes\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# mean_squared_error(y_test, final_model.predict(X_test_final), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this value mean in the current business context?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate text\n",
    "\"\"\"\n",
    "The RMSE is around 47.4.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary style=\"cursor: pointer\">Solution (click to reveal)</summary>\n",
    "    <p>This means that for an average LEGO set, this algorithm will be off by about $47. Given that most LEGO sets sell for less than $100, we would definitely want to have a human double-check and adjust these prices rather than just allowing the algorithm to set them</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret the Final Model\n",
    "\n",
    "Below, we display the coefficients and intercept for the final model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run this cell without changes\n",
    "# print(pd.Series(final_model.coef_, index=X_train_final.columns, name=\"Coefficients\"))\n",
    "# print()\n",
    "# print(\"Intercept:\", final_model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret these values below. What is the pricing algorithm you have developed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate text\n",
    "\"\"\"\n",
    "The intercept is 9.6. That's the starting point of pricing, as if a lego set had 0 pieces! \n",
    "Price goes up with piece count and difficulty level, but down with max age.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary style=\"cursor: pointer\">Solution (click to reveal)</summary>\n",
    "    <p>According to our model, the base price for a LEGO set (the model intercept) is about $9.68. Then for each additional LEGO piece in the set, the price goes up by $0.09 per piece. For every year higher that the maximum age is, the price goes down by about $0.04. Then finally for every increase of 1 in the difficulty level, the price goes up by about $2.04.</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before assuming that these coefficients give us inferential insight into past pricing decisions, we should investigate each of the assumptions of linear regression, in order to understand how much our model violates them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigating Linearity\n",
    "\n",
    "First, let's check whether the linearity assumption holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run this cell without changes\n",
    "\n",
    "# preds = final_model.predict(X_test_final)\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# perfect_line = np.arange(y_test.min(), y_test.max())\n",
    "# ax.plot(perfect_line, linestyle=\"--\", color=\"orange\", label=\"Perfect Fit\")\n",
    "# ax.scatter(y_test, preds, alpha=0.5)\n",
    "# ax.set_xlabel(\"Actual Price\")\n",
    "# ax.set_ylabel(\"Predicted Price\")\n",
    "# ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=y_train_preds, y=y_train)\n",
    "sns.lineplot(x=y_train_preds, y=y_train_preds, color='red')\n",
    "\n",
    "plt.title('Actual vs. Predicted (Training Set)')\n",
    "plt.xlabel('Predicted (log(1+$))')\n",
    "plt.ylabel('Actual (log(1+$))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds = linreg.predict(X_val)\n",
    "\n",
    "\n",
    "sns.scatterplot(x=y_val_preds, y=y_val)\n",
    "sns.lineplot(x=y_val_preds, y=y_val_preds, color='red')\n",
    "plt.title('Actual vs. Predicted (Validation Set)')\n",
    "plt.xlabel('Predicted (log(1+$))')\n",
    "plt.ylabel('Actual (log(1+$))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are we violating the linearity assumption?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate text\n",
    "\"\"\"\n",
    "Not violating linearity assumption\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary style=\"cursor: pointer\">Solution (click to reveal)</summary>\n",
    "    <p>We have some outliers that are all over the place, but in general it looks like we have a linear relationship (not violating this assumption)</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigating Normality\n",
    "\n",
    "Now let's check whether the normality assumption holds for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run this code without changes\n",
    "# import scipy.stats as stats\n",
    "\n",
    "# residuals = (y_test - preds)\n",
    "# sm.graphics.qqplot(residuals, dist=stats.norm, line='45', fit=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.graphics.qqplot(model.resid, line='45', fit=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are we violating the normality assumption?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate text\n",
    "\"\"\"\n",
    "Graph looks off. I would say we could be violating normality.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary style=\"cursor: pointer\">Solution (click to reveal)</summary>\n",
    "    <p>Our outliers are again causing problems. This is bad enough that we can probably say that we are violating the normality assumption</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigating Homoscedasticity\n",
    "\n",
    "Now let's check whether the model's errors are indeed homoscedastic or if they violate this principle and display heteroscedasticity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run this cell without changes\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# ax.scatter(preds, residuals, alpha=0.5)\n",
    "# ax.plot(preds, [0 for i in range(len(X_test))])\n",
    "# ax.set_xlabel(\"Predicted Value\")\n",
    "# ax.set_ylabel(\"Actual - Predicted Value\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Yscaled, model.resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are we violating the homoscedasticity assumption?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate text\n",
    "\"\"\"\n",
    "looks like violating homoscedasticity. this looks more hetero\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Assumptions Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary style=\"cursor: pointer\">Solution (click to reveal)</summary>\n",
    "    <p>This is not the worst \"funnel\" shape, although the residuals do seem to differ some based on the predicted price. We are probably violating a strict definition of homoscedasticity.</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations & Next Steps \n",
    "\n",
    "\n",
    "Given your answers above, how should we interpret our model's coefficients? Do we have a model that can be used for inferential as well as predictive purposes? What might your next steps be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace None with appropriate text\n",
    "\"\"\"\n",
    "I think the model is good enough but not perfect. I wouldn't present it to my boss without further refinement.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary style=\"cursor: pointer\">Solution (click to reveal)</summary>\n",
    "    <p>Our confidence in these coefficients should not be too high, since we are violating or close to violating more than one of the assumptions of linear regression. This really only should be used for predictive purposes.</p>\n",
    "    <p>A good next step here would be to start trying to figure out why our outliers behave the way they do. Maybe there is some information we could extract from the text features that are currently not part of the model</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank You"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done! As you can see, regression can be a challenging task that requires you to make decisions along the way, try alternative approaches, and make ongoing refinements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": false,
  "vscode": {
   "interpreter": {
    "hash": "7525ddc99344d304bee386e4294f627a69ef3ddf90a93199e89e426185c49e1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
